{
    "contents" : "---\ntitle: \"Regresja prosta w R\"\nauthor: \"A. M. Machno\"\ndate: \"8 października 2015\"\noutput: html_document\n---\n\n##Regresja prosta\n\nRegresja jest to podstawowy model opisujący współzależność zjawisk. Zajmiemy sie w tym rozdziale regresją prostą czyli liniowym opisem zależności dwóch zmiennych. Przeanalizujemy znów przykład na podstawie danych `mtcars`. Funkcja, która dopasowuje model regresji liniowej do danych  w R to `lm`. Zachęcam do dokładnego przeczytrania opisu działania tej funkcji `?lm`.\n\nZbadajmy liniową zależność między spalaniem, objetością silnika.\n\n```{r, cache=T}\ndata(mtcars)\n\n#dopasowujemy model liniowy zależności spalania (zmienna objaśniana) od objętości silnika\nfit.mpg.disp<-lm(mpg~disp, data=mtcars)\n\n#podsumowanie wyników estymacji\nsummary(fit.mpg.disp)\n```\n\nW podsumowaniu mamy większość interesujących wartości. Najważniejsze z praktycznego punktu widzenia są parametry modelu. W naszym modelu mamy dwa parametry. Parametr $\\beta_0$ (wyraz wolny, `intercept`) interpretujemy jako wartość oczekiwaną zmiennej objaśnianej w przypadku, gry zmienna objaśniająca jest równa 0. W naszym przypadku ta interpretacja jest raczej mało sensowna ponieważ mówi o tym, że gdyby samochód miał silnik o pojemności 0 cu.in. (cale sześcienne) to przejechałby 29.6 mil na galonie. Parametr $\\beta_1$ (`disp`) mówi nam ile średnio wzrośnie wartość zmiennej objaśnianej przy wzroście zmiennej objaśniającej o jedną jednostkę. W naszym przypadku, gdy samochód ma pojemność większo o 1 cu.in. to przejeżdża na galonie o średnio 0.04 mili.\n\nNie mniej ważne od wartości parametrów są istotności parametrów. W naszym przypadku, oba parametry są istotne (ostatnia kolumna tabeli z parametrami, `Pr(>|t|)`)\n\n##Problemy w regresji prostej.\n\nJest wiele rzeczy na które należy zwrócić uwagę przy budowie modelu. Regresja prosta jest dobrym modelem, aby zrozumieć i skwantyfikować zależność między dwoma zmiennymi. Należy jednak pamiętać, że zalezność między zmiennymi musi być liniowa (w przybliżeniu), aby interpretacja wyników była prawdziwa. \nInnym problemem są zależności między zmiennymi nie uwzględnionymi w modelu. Bardziej technicznym problemem jest homoskedastyczność, która mówi o tym, iż wariancja jest równa dla każdego poziomu zmiennej objaśniającej. Dla naszego przykładu znaczyłoby to iż odchylenie od średniej spalania dla samochodu z silnikiem o pojemności 160 cu.in. jest takie samo jak dla samochodu z silnikiem 360 cu.in. To założenie w wielu przypadkach nie jest spełnione.\n\nPierwszym badaniem, czy model regresji liniowej jest odpowiedni jest analiza wykresów. Po pierwsze stwórzmy wykres zależności `mpg`od `disp` oraz narysujmy prostą wyestymowanej regresji.\n\n```{r}\n#dla wygody przypiszemy odpowiednie zmienne do x i y\nx<-mtcars$disp\ny<-mtcars$mpg\n#model regresji dla x i y\nfit.lm<-lm(y~x)\n\n#współczynniki\nbeta0<-coef(fit.lm)[1]\nbeta1<-coef(fit.lm)[2]\n\n#prosta regresji\ncurve(beta0+beta1*x, from = min(x), to = max(x), col='red', ylim=c(min(y), max(y)),\n      xlab='pojemność silnika (cu.in.)', ylab='spalanie (mpg)')\npoints(x,y)\n\n```\n\nAby łatwiej zdiagnozować ewentualne problemy z modelem regresji należy stworzyć wykres reszt z modelu. Reszty z modelu to róznica między zobserwowaną wartościa a wartościa średnią wynikająca z modelu. W przypadku modelu liniowego to odległość w lini pionowej punktu od prostej regresji (punkty pod prostą mają ujemne reszty). Aby stworzyć wktor reszt użyjemy funkcji `resid`.\n\n```{r}\n#tworzymy wektor reszt z modelu\nres.lm<-resid(fit.lm)\n\n#wykres\nplot(x, res.lm,  xlab='pojemność silnika (cu.in.)', ylab='reszta', pch=19, col='red')\nabline(h=0)\n```\n\n##Test modelu\n\nW przypadku modelu regresji prostej, istotność parametrów mówi nam o tym, czy model jest odpowiedni. Dla większej ilości zmiennych objasniających moglibyśmy się zastanawiać czy dodatkowe zmienne wprowadzają dodatkowe informacje do modelu.\n\nW najprostszym przypadku możemy przetestować czy zmienna objaśniana jest rzeczywiście zalezna od zmiennej objaśniającej. Drugim testem jest test czy może  wyraz wolny ($\\beta_0$) jest istotnie różny id zera. Do testowania istotności modelu w stosunku do innego modelu (muszą to być modele zagnieżdżone) służy funkcja `anova`.\n\nZobaczmy jak działa test `anova` w dwóch najprostszych przypadkach. Najpierw regresja liniowa względem modelu bez zmiennej objaśniającej\n\n```{r}\n#dopasowujemy model bez zmiennej x\nfit.0<-lm(y~1)\n\n#przeprowadzamy trst anova dla fit.lm i fit.0\nanova(fit.lm, fit.0)\n```\n\nZauważmy, że p-value tego modelu jest dokładnie takie jak p-value dla o istotności parametru `disp` w modelu `fit.lm`.\n\nDrugim przypadkiem jest regresja liniowa względem regresji liniowej o wyrazie wolnym równy 0.\n\n```{r}\n#dopasowujemy model z beta0=0\nfit.1<-lm(y~x-1)\n\n#przeprowadzamy trst anova dla fit.lm i fit.1\nanova(fit.lm, fit.1)\n```\n\n",
    "created" : 1444295955298.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2723491919",
    "id" : "928C7612",
    "lastKnownWriteTime" : 1444311602,
    "path" : "C:/Users/Artur/Dropbox/AGH/dydaktyka/statystyka ZiP/2015-2016/R/R_SimpleReg.Rmd",
    "project_path" : "R_SimpleReg.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "type" : "r_markdown"
}